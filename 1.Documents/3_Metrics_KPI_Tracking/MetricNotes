# METRIC MAPPING & SCORING SYSTEM - Complete Architecture Guide

**Version:** 2.0  
**Last Updated:** December 3, 2025  
**Module:** Metrics & KPI Tracking (Section 3) + Form Templates (Section 4)  

---

## RELATED DOCUMENTS

- **FormItemMetricMapping_Guide.md** - Field-level metric mapping details
- **Section_Level_Metrics_Guide.md** - Section-level aggregation configuration
- **Template_Level_Metrics_Guide.md** - Template-level metrics (content & process)

---

## TABLE OF CONTENTS

1. [The Metric Hierarchy](#1-the-metric-hierarchy)
2. [Core Database Tables](#2-core-database-tables)
3. [Tenant-Level Metrics](#3-tenant-level-metrics)
4. [The Four Mapping Types Explained](#4-the-four-mapping-types-explained)
5. [Scoring System Architecture](#5-scoring-system-architecture)
6. [Complete Data Flow Examples](#6-complete-data-flow-examples)
7. [Advanced Scenarios & Best Practices](#7-advanced-scenarios--best-practices)

---

## 1. THE METRIC HIERARCHY

### 1.1 Four-Level Architecture

The system implements a hierarchical metric structure where higher levels aggregate data from lower levels:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   METRIC HIERARCHY                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

LEVEL 0: FIELD-LEVEL METRICS
‚îú‚îÄ Source: Individual form field responses
‚îú‚îÄ Examples: LAN Status=50pts, Total Computers=25
‚îú‚îÄ See: FormItemMetricMapping_Guide.md
‚îî‚îÄ Foundation for all higher-level metrics

LEVEL 1: SECTION-LEVEL METRICS
‚îú‚îÄ Source: Aggregated from field-level metrics
‚îú‚îÄ Examples: Infrastructure Section=72%, Hardware Section=90%
‚îú‚îÄ See: Section_Level_Metrics_Guide.md
‚îî‚îÄ Enables section-by-section analysis

LEVEL 2: TEMPLATE-LEVEL METRICS
‚îú‚îÄ Source: Aggregated from section metrics + workflow metadata
‚îú‚îÄ Examples: Overall ICT Score=79%, Submission Timeline=2.3 days
‚îú‚îÄ See: Template_Level_Metrics_Guide.md
‚îî‚îÄ Holistic view of entire form

LEVEL 3: TENANT-LEVEL METRICS
‚îú‚îÄ Source: Aggregated across all templates/factories
‚îú‚îÄ Examples: Regional ICT Average=85%, Total Forms Submitted=47
‚îú‚îÄ See: Section 3 below
‚îî‚îÄ Organizational summaries
```

### 1.2 Hierarchical Data Flow

```
USER SUBMITS FORM
    ‚Üì
FIELD METRICS POPULATE
(LAN=50, WAN=100, Servers=75)
    ‚Üì
SECTION METRICS CALCULATE
(Infrastructure = (50+100+75)/3 = 75%)
    ‚Üì
TEMPLATE METRICS CALCULATE
(Overall ICT = weighted avg of sections = 79%)
    ‚Üì
TENANT METRICS UPDATE
(Regional Average updates from 84% to 85%)
```

### 1.3 Drill-Down Capability

The hierarchy enables complete traceability:

**Dashboard:** "Regional ICT Health: 85% üü¢"
   ‚Üì Click
**Factory List:**
- Kangaita: 79% üü°
- Sotik: 91% üü¢
- Ragati: 88% üü¢
   ‚Üì Click Kangaita
**Section Breakdown:**
- Infrastructure: 72% üü°
- Software: 85% üü¢
- Hardware: 90% üü¢
   ‚Üì Click Infrastructure
**Field Details:**
- LAN Status: 50pts (Faulty)
- WAN Status: 100pts (Operational)
- Server Status: 75pts (Partial)

---

## 2. CORE DATABASE TABLES

### 2.1 Table Overview

**CONFIGURATION TABLES (Setup)**
- **MetricDefinitions** - Catalog of all metrics with thresholds
- **FormItemMetricMappings** - Maps fields to metrics (field-level)
- **SectionMetricMappings** - Maps sections to metrics (section-level)
- **TemplateMetricMappings** - Maps templates to metrics (template-level)

**DATA TABLES (Runtime)**
- **FormTemplateResponses** - User's form field answers
- **TenantMetrics** - Final calculated metric values (all levels)
- **MetricPopulationLog** - Audit trail of metric calculations

### 2.2 MetricDefinitions - Key Columns

**MetricId, MetricCode, MetricName** - Identity

**Category** (Optional)
- Groups related metrics: "Hardware", "Network", "Software", "Assessment"
- Enables category-based filtering

**SourceType** (Required) - HOW metric data is obtained
- "UserInput" - Direct from form field
- "SystemCalculated" - Computed using formulas
- "ExternalSystem" - Fetched from external APIs
- "ComplianceTracking" - Deadline/timeline monitoring
- "AutomatedCheck" - Hangfire background jobs

**DataType** (Required) - FORMAT of metric value
- "Integer", "Decimal", "Percentage", "Boolean", "Text", "Duration", "Date", "DateTime"

**Unit** (Optional) - Display unit
- "Count", "Percentage", "Points", "GB", "MB", "Days", "Hours"
- Used for formatting: Value=85.5, Unit="Percentage" ‚Üí "85.5%"

**AggregationType** (Optional) - HOW to aggregate
- "SUM" - Add all values
- "AVG" - Average of values
- "MAX", "MIN" - Highest/lowest value
- "LAST_VALUE" - Most recent
- "COUNT" - Count of records
- "NONE" - No aggregation

**IsKPI** (Boolean) - Marks Key Performance Indicators
- true = Featured prominently, threshold-based alerts
- false = Regular metric

**Thresholds** - Traffic light logic
- **ThresholdGreen** - Minimum for üü¢ good performance
- **ThresholdYellow** - Minimum for üü° warning
- Below Yellow = üî¥ critical

**MetricScope** (NEW) - Hierarchical level
- "Field", "Section", "Template", "Tenant"

**HierarchyLevel** (NEW) - Numeric level
- 0=Field, 1=Section, 2=Template, 3=Tenant

**ParentMetricId** (NEW) - Links to parent metric
- Enables drill-down navigation

**AggregationFormula** (NEW) - JSON formula
- How to aggregate lower-level metrics

### 2.3 TenantMetrics - Key Columns

**MetricValueId** - Primary key

**TenantId** - Which organization/factory

**MetricId** - Which metric (from MetricDefinitions)

**ReportingPeriod** - Time period (date)

**NumericValue** - The calculated metric value

**TextValue** - Optional text representation

**MetricScope** (NEW) - Level indicator
- "Field", "Section", "Template", "Tenant"

**SourceSectionId** (NEW) - If section-level metric

**SourceTemplateId** (NEW) - If template-level metric

**SourceItemId** (NEW) - If field-level metric

**DrillDownData** (NEW) - JSON breakdown
- Details of contributing values
- Enables drill-down in UI

**SourceReferenceId** - Links to source (SubmissionId)

**CapturedDate, CapturedBy** - Audit fields

---

## 3. TENANT-LEVEL METRICS

### 3.1 Purpose

Tenant-level metrics provide the highest organizational view, aggregating data across:
- All templates
- All factories
- All time periods

### 3.2 Tenant Metric Types

**Type 1: Cross-Template Aggregates**
Combine same metric across all factories.

Example: "Regional ICT Health Average" = Average of all factory ICT scores

**Type 2: Multi-Template Summaries**
Aggregate different templates together.

Example: "Overall Compliance Rate" = Across Safety, ICT, HR, Finance forms

**Type 3: Organization-Wide Counts**
System-level statistics.

Examples:
- Total forms submitted this month
- Total users active
- Total factories reporting

**Type 4: Performance Trends**
Compare current vs previous periods.

Examples:
- Month-over-month improvement
- Year-over-year comparison
- Trend direction (improving/declining)

### 3.3 Configuration

Tenant metrics typically don't have explicit mappings. They're calculated by:

**Method 1: Scheduled Aggregation Jobs**
Hangfire jobs run daily/weekly/monthly to:
- Query TenantMetrics with MetricScope="Template"
- Group by MetricId
- Calculate AVG, SUM, COUNT, etc.
- Save result with MetricScope="Tenant"

**Method 2: On-Demand Calculation**
Dashboard queries calculate in real-time:
- Not stored in TenantMetrics
- Computed from underlying data
- Cached for performance

### 3.4 Example: Regional Average ICT Health

**Metric Definition:**
- MetricCode: "REGIONAL_ICT_HEALTH_AVERAGE"
- MetricScope: "Tenant"
- AggregationType: "AVG"

**Calculation:**
Query all factories' ICT Overall Scores for November:
- Kangaita: 79.75%
- Sotik: 91.0%
- Ragati: 88.5%
- Mataara: 82.0%
- Kipkelion: 85.5%

Regional Average = (79.75 + 91.0 + 88.5 + 82.0 + 85.5) / 5 = 85.35%

**Result in TenantMetrics:**
- MetricScope: "Tenant"
- TenantId: 1 (Regional Office)
- MetricId: 301
- NumericValue: 85.35
- DrillDownData: Contains breakdown by factory

**Dashboard Display:**
"Regional ICT Health: 85.35% üü¢"

### 3.5 Drill-Down from Tenant Level

**Executive Dashboard:**
"Regional ICT Health: 85.35% üü¢"

**Drill Down Level 1 - By Factory:**
- Kangaita: 79.75% üü°
- Sotik: 91.0% üü¢
- Ragati: 88.5% üü¢

**Drill Down Level 2 - Kangaita Sections:**
- Infrastructure: 72.5% üü°
- Software: 85% üü¢
- Hardware: 90% üü¢

**Drill Down Level 3 - Infrastructure Fields:**
- LAN Status: 50 pts
- WAN Status: 100 pts
- Server Status: 75 pts

Complete traceability from executive summary to individual field responses.

---

## 4. THE FOUR MAPPING TYPES EXPLAINED

### 4.1 Type 1: Direct Mapping

**Use When:** Field value becomes metric value with NO transformation.

**How It Works:**
1. User enters value
2. System reads ResponseValue
3. Saves to TenantMetrics (no change)

**Example 1: Inventory Count**
- Field: "Total Computers" = 25
- Mapping: Direct
- Metric: TOTAL_COMPUTERS = 25

**Example 2: Status with Scores**
- Field: "LAN Status" = "Faulty"
- Option "Faulty" has ScoreValue: 50
- Mapping: Direct (uses score)
- Metric: LAN_EQUIPMENT_HEALTH = 50

**When to Use:**
- Simple inventory tracking
- Direct measurements
- Pre-scored option selections

### 4.2 Type 2: SystemCalculated (Formula-Based)

**Use When:** Metric computed from multiple field values using a formula.

**Variable Syntax:**
- **item{ItemId}** = Form field value (from FormTemplateResponses)
- **metric{MetricId}** = Another metric value (from TenantMetrics)

**Example 1: Availability Percentage**

Formula: `(item46 / item45) * 100`

Field Data:
- Item 45: "Total Computers" = 25
- Item 46: "Operational Computers" = 20

Calculation: (20 / 25) √ó 100 = 80.0%

Result: Metric COMPUTER_AVAILABILITY_PCT = 80.0

**Example 2: Section Score from Metrics**

Formula: `metric201 * 0.5 + metric202 * 0.3 + metric203 * 0.2`

Metric Data:
- Metric 201: Infrastructure = 72.5
- Metric 202: Software = 85.0
- Metric 203: Hardware = 90.0

Calculation: (72.5√ó0.5) + (85√ó0.3) + (90√ó0.2) = 79.75

Result: Metric ICT_OVERALL_SCORE = 79.75

**Processing Order:**
- **item{Id}** formulas process first (depend on form data)
- **metric{Id}** formulas process second (depend on other metrics)

**TransformationLogic JSON:**
```json
{
  "formula": "(item46 / item45) * 100",
  "items": [45, 46],
  "sourceMetrics": [],
  "roundTo": 2
}
```

### 4.3 Type 3: BinaryCompliance

**Use When:** Converting Yes/No answers to 100%/0% for compliance tracking.

**How It Works:**
1. Read response value
2. Compare to ExpectedValue
3. Match ‚Üí 100% (1.0)
4. No match ‚Üí 0% (0.0)

**Example: Equipment Operational**

Field: "Is LAN Operational?"
Response: "Yes"
ExpectedValue: "Yes"
Comparison: "Yes" == "Yes" ‚Üí TRUE
Result: Metric = 1.0 (100%)

**Example: Safety Check**

Field: "Safety Protocol Completed?"
Response: "No"
ExpectedValue: "Yes"
Comparison: "No" == "Yes" ‚Üí FALSE
Result: Metric = 0.0 (0%)

**Aggregation for Compliance Rates:**
Multiple factories:
- Factory A: 1.0 (compliant)
- Factory B: 1.0 (compliant)
- Factory C: 0.0 (non-compliant)
- Factory D: 1.0 (compliant)
- Factory E: 0.0 (non-compliant)

Regional Compliance = AVG(1.0, 1.0, 0.0, 1.0, 0.0) = 60%

**When to Use:**
- Safety compliance tracking
- Policy adherence monitoring
- Binary status checks
- Go/No-go decisions

### 4.4 Type 4: ScoreMapping

**Use When:** Multiple fields contribute scores to a single aggregate metric.

**How It Works:**
1. Identify all fields mapped to same metric with ScoreMapping type
2. For each field:
   - Get response value
   - Lookup score (FormItemOption.ScoreValue)
   - Apply weight (if configured)
3. Sum all scores
4. Save ONE aggregate entry

**Example: ICT Assessment Form**

Fields contributing to Metric 101 (ICT_INFRASTRUCTURE_SCORE):

- Q1 (Item 45): LAN Status = "Partial" ‚Üí 5 points
- Q2 (Item 46): Network Speed = "Good" ‚Üí 7 points
- Q3 (Item 47): Hardware = "Fair" ‚Üí 5 points
- Q4 (Item 48): Software = "Good" ‚Üí 7 points
- Q5 (Item 49): Licenses = "Excellent" ‚Üí 10 points

Total Score: 5 + 7 + 5 + 7 + 10 = 34 points

**Result in TenantMetrics:**
ONE record (not five):
- MetricId: 101
- NumericValue: 34.0
- DrillDownData: '{"Q1":5, "Q2":7, "Q3":5, "Q4":7, "Q5":10}'

**Weighted Scoring:**
If Q1 is more critical (weight=2.0):
- Q1: 5 √ó 2.0 = 10 points
- Q2-Q5: 7+5+7+10 = 29 points
- Total: 39 points (weighted)

### 4.5 Mapping Type Selection Guide

**Choose Direct when:**
- No calculation needed
- Field value = Metric value
- Simple one-to-one relationship

**Choose SystemCalculated when:**
- Need formula/expression
- Combining multiple fields
- Mathematical operations
- Aggregating section/template scores

**Choose BinaryCompliance when:**
- Yes/No questions
- Compliance tracking
- Need percentage pass rate

**Choose ScoreMapping when:**
- Assessment forms
- Multiple questions contribute to score
- Pre-scored options
- Need total/aggregate points

---

## 5. SCORING SYSTEM ARCHITECTURE

### 5.1 The FormItemOption.ScoreValue Column

**Purpose:** Enable numeric scoring for fields with options (Dropdown, Radio, Checkbox).

**Example: LAN Equipment Status**

Options with scores:
- "Fully Operational" ‚Üí OptionValue: "operational", ScoreValue: 100
- "Partially Operational" ‚Üí OptionValue: "partial", ScoreValue: 50
- "Not Operational" ‚Üí OptionValue: "not_operational", ScoreValue: 0

**User Submission:**
Selects "Partially Operational"

**System Processing:**
1. Reads ResponseValue: "partial"
2. Looks up FormItemOption WHERE OptionValue = "partial"
3. Retrieves ScoreValue: 50
4. Uses 50 as the metric value

### 5.2 Two-Tab Workflow

**TAB 1: Scoring Configuration**
Configure HOW field produces measurable values.

For fields with options:
- Assign score values to each option
- Example: Excellent=10, Good=7, Fair=5, Poor=2

For numeric fields:
- Use field value directly (counting, totals)

For text fields:
- Cannot produce numeric scores (text-only)

**TAB 2: Metric Mapping**
Connect configured field to metrics.

System intelligently filters compatible metrics based on:
- Field's DataType matches Metric's DataType
- Field's scoring capability matches Metric's SourceType
- Category/context suggests relevant metrics

### 5.3 Smart Metric Filtering

**Field with numeric scoring (options with ScoreValues):**
‚úÖ Show metrics: DataType = Integer/Decimal/Percentage
‚úÖ Show metrics: SourceType = UserInput/SystemCalculated
‚ùå Hide metrics: DataType = Text
‚ùå Hide metrics: SourceType = ExternalSystem

**Field with pure text (no scoring):**
‚úÖ Show metrics: DataType = Text
‚ùå Hide numeric metrics

### 5.4 Complete Assessment Example

**Form:** "ICT Infrastructure Assessment"

**Sections:**

**Section 1: Network (20 pts max)**
- Q1: LAN Status (10 pts) - Fully=10, Partial=5, Not=0
- Q2: Network Speed (10 pts) - Excellent=10, Good=7, Fair=5, Poor=2

**Section 2: Hardware (20 pts max)**
- Q3: Computer Availability (10 pts)
- Q4: Hardware Age (10 pts)

**Section 3: Software (10 pts max)**
- Q5: License Compliance (10 pts)

**Metrics:**

1. NETWORK_SECTION_SCORE (Section-level, max 20)
2. HARDWARE_SECTION_SCORE (Section-level, max 20)
3. SOFTWARE_SECTION_SCORE (Section-level, max 10)
4. ICT_TOTAL_ASSESSMENT_SCORE (Template-level, max 50)

**User Submission:**
- Q1: Partial (5)
- Q2: Good (7)
- Q3: Fair (5)
- Q4: Good (7)
- Q5: Excellent (10)

**Results:**

Section-Level:
- NETWORK = 12 (5+7)
- HARDWARE = 12 (5+7)
- SOFTWARE = 10

Template-Level:
- ICT_TOTAL = 34 (12+12+10)
- Status: üü° Yellow (34 < 35 for Green, ‚â•35 threshold)

---

## 6. COMPLETE DATA FLOW EXAMPLES

### 6.1 Example 1: Simple Direct Mapping

**Setup:**
- Metric: TOTAL_COMPUTERS (Field-level)
- Field: "Number of Computers" (Number)
- Mapping: Direct

**User Action:**
Kangaita submits: "Number of Computers" = 25

**Processing:**

1. Form saved ‚Üí Creates FormTemplateSubmission (ID: 789)
2. Response saved ‚Üí FormTemplateResponse (ItemId: 45, Value: "25")
3. Approval triggers MetricPopulationService
4. Service finds mapping (ItemId 45 ‚Üí MetricId 12, Type: Direct)
5. Reads value: "25"
6. Saves to TenantMetrics:
   - TenantId: 5 (Kangaita)
   - MetricId: 12
   - NumericValue: 25.0
   - MetricScope: "Field"

**Dashboard:** "Kangaita - Total Computers: 25"

### 6.2 Example 2: Calculated KPI

**Setup:**
- Metric 12: TOTAL_COMPUTERS
- Metric 13: OPERATIONAL_COMPUTERS
- Metric 14: COMPUTER_AVAILABILITY_PCT (Calculated)
  - Formula: "(item46 / item45) * 100"

**User Action:**
Kangaita submits: Total=25, Operational=20

**Processing:**

Phase 1: Direct Mappings
- Saves MetricId 12 = 25.0
- Saves MetricId 13 = 20.0

Phase 2: Calculated Mappings
- Retrieves item45=25, item46=20
- Evaluates: (20/25)*100 = 80.0
- Saves MetricId 14 = 80.0
- Logs to MetricPopulationLog

Phase 3: Threshold Evaluation
- ThresholdGreen: 95.0 ‚Üí 80.0 < 95 ‚Üí Not Green
- ThresholdYellow: 85.0 ‚Üí 80.0 < 85 ‚Üí Not Yellow
- Result: üî¥ Red

**Dashboard:** "Computer Availability: 80% üî¥ (Below 85% target)"

### 6.3 Example 3: Multi-Level Assessment

**Setup:**
- Field-level: Individual question scores
- Section-level: INFRASTRUCTURE_SECTION_SCORE, SOFTWARE_SECTION_SCORE, HARDWARE_SECTION_SCORE
- Template-level: ICT_OVERALL_ASSESSMENT_SCORE
- Tenant-level: REGIONAL_ICT_HEALTH_AVERAGE

**User Action:**
Kangaita submits November ICT report:
- Infrastructure fields: LAN=50, WAN=100, Servers=75
- Software fields: Updates=85, Licenses=100
- Hardware fields: Computers=95, Age=85

**Processing:**

**LEVEL 1: Section Metrics**

Infrastructure:
- Weighted avg: (50√ó0.4)+(100√ó0.3)+(75√ó0.3) = 72.5%
- Saves: MetricId 201=72.5, MetricScope="Section"

Software:
- Average: (85+100)/2 = 92.5%
- Saves: MetricId 202=92.5, MetricScope="Section"

Hardware:
- Average: (95+85)/2 = 90.0%
- Saves: MetricId 203=90.0, MetricScope="Section"

**LEVEL 2: Template Metrics**

Overall Score:
- Formula: metric201√ó0.5 + metric202√ó0.3 + metric203√ó0.2
- Calculation: (72.5√ó0.5)+(92.5√ó0.3)+(90√ó0.2) = 79.75%
- Saves: MetricId 301=79.75, MetricScope="Template"

**LEVEL 3: Tenant Metrics**

Regional Average (after all factories submit):
- Kangaita: 79.75%
- Sotik: 91.0%
- Ragati: 88.5%
- Average: 86.42%
- Saves: MetricId 401=86.42, MetricScope="Tenant"

**Dashboard Drill-Down:**

Regional View: "Regional ICT: 86.42% üü¢"
   ‚Üì
Factory View: "Kangaita: 79.75% üü°"
   ‚Üì
Section View: "Infrastructure: 72.5% üü°"
   ‚Üì
Field View: "LAN: 50pts (Faulty)"

---

## 7. ADVANCED SCENARIOS & BEST PRACTICES

### 7.1 Processing Order for Formulas

**Dependency Graph:**

When formulas reference other metrics, process in correct order:

1. **Level 0: Field-level Direct** - No dependencies
2. **Level 1: Field-level Calculated (item{Id})** - Depends on form fields only
3. **Level 2: Section-level** - Depends on field metrics
4. **Level 3: Template-level** - Depends on section metrics
5. **Level 4: Field-level Calculated (metric{Id})** - Depends on other metrics
6. **Level 5: Tenant-level** - Depends on template metrics

**Example:**

```
Metric A: Direct (Item 45)              ‚Üí Process at Level 0
Metric B: Direct (Item 46)              ‚Üí Process at Level 0
Metric C: Calculated (item45 + item46)  ‚Üí Process at Level 1
Metric D: Section (avg of A, B, C)      ‚Üí Process at Level 2
Metric E: Template (D √ó 0.5)            ‚Üí Process at Level 3
Metric F: Calculated (metric E √ó 2)     ‚Üí Process at Level 4
Metric G: Tenant (avg of all F)         ‚Üí Process at Level 5
```

### 7.2 Circular Dependency Prevention

**‚ùå WRONG - Circular Reference:**
```
Metric 201: formula = "metric202 + 10"  ‚Üí Depends on 202
Metric 202: formula = "metric201 * 2"   ‚Üí Depends on 201
DEADLOCK! Neither can be calculated.
```

**‚úÖ CORRECT - Linear Chain:**
```
Metric 201: formula = "item45 + item46"  ‚Üí Depends on form fields
Metric 202: formula = "metric201 * 2"    ‚Üí Depends on 201 (OK)
Metric 203: formula = "metric202 + 10"   ‚Üí Depends on 202 (OK)
```

### 7.3 Variable Syntax Rules

**item{ItemId} - Form Field Variables**
- Source: FormTemplateResponses table
- Available: Immediately after form submission
- Example: `item45` references ItemId 45's response value

**metric{MetricId} - Metric Variables**
- Source: TenantMetrics table
- Available: After source metric is calculated
- Example: `metric201` references MetricId 201's calculated value

**Common Mistake:**
```
‚ùå Using "item" for metric reference
Formula: "item201 + item202"  // Wrong if 201, 202 are metrics

‚úÖ Use correct prefix
Formula: "metric201 + metric202"  // Correct for metrics
```

### 7.4 TransformationLogic JSON Structure

**For SystemCalculated mappings:**

```json
{
  "formula": "(item46 / item45) * 100",
  "items": [45, 46],
  "sourceMetrics": [],
  "roundTo": 2,
  "defaultValue": 0
}
```

**For ScoreMapping:**

```json
{
  "scoreSource": "option",
  "contributesTo": "total",
  "weight": 1.0
}
```

**For BinaryCompliance:**

```json
{
  "expectedValue": "Yes",
  "complianceValue": 1.0,
  "nonComplianceValue": 0.0
}
```

### 7.5 Best Practices

**1. Naming Conventions**
- Field metrics: `{CATEGORY}_{NAME}` (e.g., TOTAL_COMPUTERS)
- Section metrics: `{SECTION_NAME}_SECTION_SCORE`
- Template metrics: `{TEMPLATE_NAME}_OVERALL_SCORE`
- Tenant metrics: `REGIONAL_{NAME}_AVERAGE`

**2. Threshold Setting**
- Green: Target/excellent performance
- Yellow: Acceptable but needs attention
- Red: Below Yellow (automatic)
- Set Yellow ‚â• 80% of Green for meaningful ranges

**3. MetricScope Usage**
- Always set MetricScope for proper aggregation
- Set HierarchyLevel for processing order
- Use ParentMetricId for drill-down links

**4. DrillDownData**
- Always populate for higher-level metrics
- Store JSON with contributing values
- Enables UI navigation and analysis

**5. Formula Validation**
- Validate formulas during mapping creation
- Check for undefined variables
- Prevent circular dependencies
- Test with sample data

**6. Aggregation Strategy**
- Use weighted averages when importance varies
- Use simple averages for equal importance
- Use SUM for point totals
- Document aggregation logic clearly

**7. Performance**
- Index MetricScope, TenantId, ReportingPeriod
- Cache frequently accessed tenant-level metrics
- Use background jobs for heavy aggregations
- Paginate drill-down queries

---

## SUMMARY

This guide covers the complete metric mapping and scoring system:

‚úÖ **Four-level hierarchy** - Field ‚Üí Section ‚Üí Template ‚Üí Tenant
‚úÖ **Four mapping types** - Direct, SystemCalculated, BinaryCompliance, ScoreMapping
‚úÖ **Scoring system** - FormItemOption.ScoreValue for assessments
‚úÖ **Smart filtering** - Compatible metric suggestions
‚úÖ **Complete data flow** - From submission to dashboard
‚úÖ **Best practices** - Processing order, naming, thresholds

For specific details:
- **Field-level metrics:** See FormItemMetricMapping_Guide.md
- **Section-level metrics:** See Section_Level_Metrics_Guide.md
- **Template-level metrics:** See Template_Level_Metrics_Guide.md

---

**End of Document**
